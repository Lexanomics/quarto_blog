{
  "hash": "c39715d2104d5fe33dd3a484d47b5f3d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Basic taxonomic classification of long and short reads with Kraken2\"\nauthor: \"Diego Gomes\"\ndate: \"2024-04-04\"\nbibliography: ref.bib\nfreeze: auto\nexecute:\n  eval: false\ncategories: [debbuging new]\n---\n\n```{=html}\n<style>\nbody {\ntext-align: justify}\n</style>\n```\n\n![Basic taxonomic classification of long and short reads with Kraken2](Fig.png)\n\nThe taxonomic classification of reads from sequencing experiments has become a common task for most computational biology and bioinformatics projects. To facilitate this process, Kraken2 was developed to make it faster and computationally less costly [@wood_improved_2019].\n\nTo assist those who are new to taxonomic classification activities and even metagenomics, we will describe a brief tutorial here for performing an analysis with Kraken2. It's worth noting that all commands shown here are extensively described in the [software's manual](https://github.com/DerrickWood/kraken2/blob/master/docs/MANUAL.markdown).\n\n### Kraken2 installation\n\n**Option 1**: Clone from github repository\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngit clone https://github.com/DerrickWood/kraken2.git\n\ncd kraken2\n\n./install_kraken2.sh ./\n```\n:::\n\n\n**Option 2**: Conda installation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconda create -n kraken2_env\n\nconda activate kraken2_env\n\nconda install kraken2:2.1.2\n```\n:::\n\n\n**Option 3** *(Only for Ubuntu based distros)*: Ubuntu repository installation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsudo apt install kraken2\n```\n:::\n\n\nAn analysis with Kraken2 occurs in two steps:\n\n1.  Building the database\n\n2.  Classification\n\n## 1. Building the Kraken2 database\n\nThe default Kraken2 database can be easily constructed by executing the following command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkraken2-build --standard --db kraken_standard\n```\n:::\n\n\nYou can speed up some steps by setting the number of threads to use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# using 30 threads\nkraken2-build --standard --threads 30 --db kraken_standard\n```\n:::\n\n\nThis process will create a directory named \"kraken_standard\" containing three files: hash.k2d; opts.k2d and taxo.k2d.\n\nThe Kraken2 standard database is composed by archaea, bacteria, plasmid, viral, UniVec_Core and human databases from GenBank, and should me enough to a basic metagenomics analysis.\n\n> **Note**: Building the standard database will require approximately 500 GB of free space on the hard drive (due to intermediate files) and 80 GB RAM, based on the data downloaded at the time of this publication.\n\n> **Tip**: rsync connection may crash sometimes. In this case, just run the command again, and Kraken2 will return to the point where the last complete library left off.\n\n## 2. Classification\n\nAfter an extensive database-building job, the time to classify your reads has come. Here I will use the \"kraken_standard\" created in the last command. You shall change this parameter to the given database that you might be creating.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkraken2 \\\n  --db kraken_standard \\\n  --output kraken_out.txt \\\n  --report kraken_report.txt \\\n  --threads 10 \\\n  gut_unmapped.fastq.gz\n```\n:::\n\n\n`--output`: Will write the taxonomic classification of each read into the *kraken_out.txt* file\n\n`--report`: Will write the the number of minimizers in the database that are mapped to the various taxa/clades into the *kraken_report.txt* file. Write this file will be useful for further analysis with Braken, Taxpasta and Krona.\n\n`gut_unmapped.fastq.gz`: Are my reads dataset that I want to classify. You may change this parameter to the path and name of the file that you are going to classify.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}